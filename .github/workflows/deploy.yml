name: Build and Deploy

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

permissions:
  contents: read
  packages: write
  security-events: write

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}/codeforces-multi-cloud-microservices

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [auth-service, contest-service, submission-service, execution-service, scoring-service, leaderboard-service]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Convert repository owner to lowercase
      id: repo
      run: echo "owner=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      id: docker
      with:
        context: ./services/${{ matrix.service }}
        push: ${{ github.event_name != 'pull_request' }}
        tags: |
          ${{ env.REGISTRY }}/${{ steps.repo.outputs.owner }}/codeforces-${{ matrix.service }}:${{ github.sha }}
          ${{ env.REGISTRY }}/${{ steps.repo.outputs.owner }}/codeforces-${{ matrix.service }}:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64
    
    - name: Run security scan
      uses: aquasecurity/trivy-action@master
      if: github.event_name != 'pull_request' && steps.docker.outcome == 'success'
      id: trivy-scan
      continue-on-error: true
      with:
        image-ref: ${{ env.REGISTRY }}/${{ steps.repo.outputs.owner }}/codeforces-${{ matrix.service }}:${{ github.sha }}
        format: 'sarif'
        output: 'trivy-results-${{ matrix.service }}.sarif'
        exit-code: '0'
    
    - name: Check if Trivy results exist
      id: check-trivy
      if: github.event_name != 'pull_request' && steps.trivy-scan.outcome != 'failure'
      run: |
        if [ -f "trivy-results-${{ matrix.service }}.sarif" ]; then
          echo "exists=true" >> $GITHUB_OUTPUT
        else
          echo "exists=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v4
      if: github.event_name != 'pull_request' && steps.check-trivy.outputs.exists == 'true'
      with:
        sarif_file: 'trivy-results-${{ matrix.service }}.sarif'
        wait-for-processing: false

  build-frontend:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Convert repository owner to lowercase
      id: repo
      run: echo "owner=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push frontend Docker image
      uses: docker/build-push-action@v4
      with:
        context: ./frontend/nextjs-app
        push: ${{ github.event_name != 'pull_request' }}
        tags: |
          ${{ env.REGISTRY }}/${{ steps.repo.outputs.owner }}/codeforces-frontend:${{ github.sha }}
          ${{ env.REGISTRY }}/${{ steps.repo.outputs.owner }}/codeforces-frontend:latest
        build-args: |
          NEXT_PUBLIC_AUTH_SERVICE_URL=http://auth-service.codeforces.svc.cluster.local:80
          NEXT_PUBLIC_CONTEST_SERVICE_URL=http://contest-service.codeforces.svc.cluster.local:80
          NEXT_PUBLIC_SUBMISSION_SERVICE_URL=http://submission-service.codeforces.svc.cluster.local:80
          NEXT_PUBLIC_LEADERBOARD_SERVICE_URL=http://leaderboard-service.codeforces.svc.cluster.local:80
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64

  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: codeforces
          POSTGRES_PASSWORD: codeforces_test
          POSTGRES_DB: codeforces_test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        cd services/auth-service
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Initialize test database
      env:
        DATABASE_URL: postgresql://codeforces:codeforces_test@localhost:5432/codeforces_test_db
        PYTHONPATH: ${{ github.workspace }}/services/auth-service
      run: |
        cd services/auth-service
        python -c "from app.database import init_db; init_db()"
    
    - name: Run tests
      env:
        DATABASE_URL: postgresql://codeforces:codeforces_test@localhost:5432/codeforces_test_db
        PYTHONPATH: ${{ github.workspace }}/services/auth-service
      run: |
        cd services/auth-service
        pytest tests/ -v --cov=app --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./services/auth-service/coverage.xml

  deploy:
    needs: [build, build-frontend, test]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
    
    - name: Configure Azure credentials
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
      continue-on-error: true
    
    - name: Terraform Init
      run: |
        cd infrastructure/terraform/aws && terraform init
        cd ../azure && terraform init
    
    - name: Terraform Plan
      continue-on-error: true
      run: |
        cd infrastructure/terraform/aws && \
        # Check if EKS cluster exists
        echo "Checking if EKS cluster exists..."
        if aws eks describe-cluster --name codeforces-aws-cluster --region us-east-1 2>&1 | grep -q "ResourceNotFoundException"; then
          echo "✗ EKS cluster does not exist, will create new cluster and VPC"
          EKS_EXISTS=false
          VPC_EXISTS=false
        else
          echo "✓ EKS cluster exists, will use existing cluster and VPC"
          EKS_EXISTS=true
          VPC_EXISTS=true
        fi && \
        terraform plan -out=tfplan \
          -var="import_existing_iam_role=true" \
          -var="import_existing_eks_cluster=$EKS_EXISTS" \
          -var="import_existing_vpc=$VPC_EXISTS" || echo "AWS plan failed"
        cd ../azure && \
        # Check if AKS cluster exists
        echo "Checking if AKS cluster exists..."
        # Detect PostgreSQL server existence with multiple methods
        echo "Checking for existing PostgreSQL server..."
        echo "Method 1: Using az resource list..."
        POSTGRES_RESOURCES=$(az resource list --resource-group codeforces-rg --resource-type Microsoft.DBforPostgreSQL/flexibleServers -o json 2>&1 || echo "[]")
        echo "Found resources: $POSTGRES_RESOURCES"
        
        echo "Method 2: Using az postgres flexible-server list..."
        POSTGRES_LIST=$(az postgres flexible-server list --resource-group codeforces-rg -o json 2>&1 || echo "[]")
        echo "Postgres list: $POSTGRES_LIST"
        
        # Initialize variables
        POSTGRES_EXISTS=false
        POSTGRES_LOOKUP=false
        POSTGRES_LOCATION="eastus"
        POSTGRES_SERVER_ID=""
        POSTGRES_SERVER_FQDN=""
        
        echo "Method 3: Direct check with az postgres flexible-server show..."
        if az postgres flexible-server show --resource-group codeforces-rg --name codeforces-postgres --output none 2>/dev/null; then
          echo "✓ PostgreSQL server 'codeforces-postgres' exists (found via show), will import"
          POSTGRES_EXISTS=true
          POSTGRES_LOOKUP=true
          # Get the server's location
          POSTGRES_LOCATION=$(az postgres flexible-server show --resource-group codeforces-rg --name codeforces-postgres --query location -o tsv 2>/dev/null || echo "eastus")
          echo "PostgreSQL server location: $POSTGRES_LOCATION"
        elif echo "$POSTGRES_LIST" | grep -q "codeforces-postgres"; then
          echo "✓ PostgreSQL server 'codeforces-postgres' exists (found via list), will import"
          POSTGRES_EXISTS=true
          POSTGRES_LOOKUP=true
          # Extract location from list output
          POSTGRES_LOCATION=$(echo "$POSTGRES_LIST" | grep -A 20 "codeforces-postgres" | grep "location" | head -1 | cut -d'"' -f4 || echo "eastus")
          echo "PostgreSQL server location: $POSTGRES_LOCATION"
        elif echo "$POSTGRES_RESOURCES" | grep -q "codeforces-postgres"; then
          echo "✓ PostgreSQL server 'codeforces-postgres' exists (found via resource list), will import"
          POSTGRES_EXISTS=true
          POSTGRES_LOOKUP=true
          # Extract location from resource list
          POSTGRES_LOCATION=$(echo "$POSTGRES_RESOURCES" | grep -A 20 "codeforces-postgres" | grep "location" | head -1 | cut -d'"' -f4 || echo "eastus")
          echo "PostgreSQL server location: $POSTGRES_LOCATION"
        else
          echo "✗ PostgreSQL server not visible via CLI; defaulting to import existing to avoid duplicate creation"
          echo "⚠️ Ensure the service principal has Reader access on the PostgreSQL server or resource group"
          POSTGRES_EXISTS=true
          POSTGRES_LOCATION="eastus"
          POSTGRES_LOOKUP=false
          # When lookup is disabled, we must provide the server ID and FQDN manually
          # Get them from Azure using available credentials
          POSTGRES_SERVER_ID=$(az resource show --ids /subscriptions/6431583b-65fa-47e3-960d-bde14e528bb6/resourceGroups/codeforces-rg/providers/Microsoft.DBforPostgreSQL/flexibleServers/codeforces-postgres --query id -o tsv 2>/dev/null || echo "/subscriptions/6431583b-65fa-47e3-960d-bde14e528bb6/resourceGroups/codeforces-rg/providers/Microsoft.DBforPostgreSQL/flexibleServers/codeforces-postgres")
          POSTGRES_SERVER_FQDN=$(echo "codeforces-postgres.postgres.database.azure.com")  # Standard naming pattern
          echo "PostgreSQL server ID: $POSTGRES_SERVER_ID"
          echo "PostgreSQL server FQDN: $POSTGRES_SERVER_FQDN"
        fi

        # Default lookup flag when not set above
        if [ -z "${POSTGRES_LOOKUP+x}" ]; then POSTGRES_LOOKUP=true; fi
        
        # Check AKS cluster existence
        if az aks show --resource-group codeforces-rg --name codeforces-aks-cluster --output json >/dev/null 2>&1; then
          echo "✓ AKS cluster exists, will use existing"
          AKS_EXISTS=true
        else
          echo "✗ AKS cluster does not exist, will create new"
          AKS_EXISTS=false
        fi || echo "⚠ Could not check AKS cluster status, will attempt to create"
        
        # Ensure AKS_EXISTS is set
        if [ -z "${AKS_EXISTS+x}" ]; then AKS_EXISTS=false; fi
        
        echo "Setting import_existing_aks_cluster=$AKS_EXISTS"
        echo "Setting import_existing_postgres=$POSTGRES_EXISTS"
        echo "Setting allow_postgres_lookup=$POSTGRES_LOOKUP"
        echo "Setting azure_location=$POSTGRES_LOCATION (using PostgreSQL server location)"
        
        # Check Azure resource group existence
        echo "Checking for existing Azure resource group..."
        if az group show --name codeforces-rg --output none 2>/dev/null; then
          echo "✓ Resource group 'codeforces-rg' exists, will import"
          RG_EXISTS=true
        else
          echo "✗ Resource group does not exist, will create new"
          RG_EXISTS=false
        fi
        
        # Check VNet existence
        echo "Checking for existing VNet..."
        if az network vnet show --resource-group codeforces-rg --name codeforces-vnet --output none 2>/dev/null; then
          echo "✓ VNet 'codeforces-vnet' exists, will import"
          VNET_EXISTS=true
        else
          echo "✗ VNet does not exist, will create new"
          VNET_EXISTS=false
        fi
        
        # Check Public IP existence
        echo "Checking for existing Public IP..."
        if az network public-ip show --resource-group codeforces-rg --name codeforces-lb-ip --output none 2>/dev/null; then
          echo "✓ Public IP 'codeforces-lb-ip' exists, will import"
          PUBLIC_IP_EXISTS=true
        else
          echo "✗ Public IP does not exist, will create new"
          PUBLIC_IP_EXISTS=false
        fi
        
        # Check Subnet main existence
        echo "Checking for existing Subnet main..."
        if az network vnet subnet show --resource-group codeforces-rg --vnet-name codeforces-vnet --name codeforces-subnet --output none 2>/dev/null; then
          echo "✓ Subnet 'codeforces-subnet' exists, will import"
          SUBNET_MAIN_EXISTS=true
        else
          echo "✗ Subnet does not exist, will create new"
          SUBNET_MAIN_EXISTS=false
        fi
        
        # Check Subnet postgres existence
        echo "Checking for existing Subnet postgres..."
        if az network vnet subnet show --resource-group codeforces-rg --vnet-name codeforces-vnet --name codeforces-postgres-subnet --output none 2>/dev/null; then
          echo "✓ Subnet postgres 'codeforces-postgres-subnet' exists, will import"
          SUBNET_POSTGRES_EXISTS=true
        else
          echo "✗ Subnet postgres does not exist, will create new"
          SUBNET_POSTGRES_EXISTS=false
        fi
        
        # Check Private DNS Zone existence - default to true if detection fails
        echo "Checking for existing Private DNS Zone..."
        DNS_ZONE_EXISTS=true
        if ! az network private-dns zone list --resource-group codeforces-rg 2>/dev/null | grep -q "codeforces.postgres.database.azure.com"; then
          DNS_ZONE_EXISTS=false
        fi
        echo "DNS_ZONE_EXISTS=$DNS_ZONE_EXISTS"
        
        # Check DNS VNet Link existence - default to true if detection fails
        echo "Checking for existing DNS VNet Link..."
        DNS_VNET_LINK_EXISTS=true
        # Try to list links, if it fails or doesn't find the link, set to false
        if ! az network private-dns link vnet list --resource-group codeforces-rg --zone-name codeforces.postgres.database.azure.com 2>/dev/null | grep -q "codeforces-vnet-link"; then
          DNS_VNET_LINK_EXISTS=false
        fi
        echo "DNS_VNET_LINK_EXISTS=$DNS_VNET_LINK_EXISTS"
        
        # Check Load Balancer existence - default to true if it exists
        echo "Checking for existing Load Balancer..."
        LB_EXISTS=true
        if ! az network lb list --resource-group codeforces-rg 2>/dev/null | grep -q "codeforces-lb"; then
          LB_EXISTS=false
        fi
        echo "LB_EXISTS=$LB_EXISTS"
        
        terraform plan -out=tfplan \
          -var="import_existing_resource_group=$RG_EXISTS" \
          -var="import_existing_vnet=$VNET_EXISTS" \
          -var="import_existing_public_ip=$PUBLIC_IP_EXISTS" \
          -var="import_existing_subnet_main=$SUBNET_MAIN_EXISTS" \
          -var="import_existing_subnet_postgres=$SUBNET_POSTGRES_EXISTS" \
          -var="import_existing_aks_cluster=$AKS_EXISTS" \
          -var="import_existing_dns_zone=$DNS_ZONE_EXISTS" \
          -var="import_existing_dns_vnet_link=$DNS_VNET_LINK_EXISTS" \
          -var="import_existing_lb=$LB_EXISTS" \
          -var="import_existing_postgres=$POSTGRES_EXISTS" \
          -var="allow_postgres_lookup=$POSTGRES_LOOKUP" \
          -var="postgres_server_id=${POSTGRES_SERVER_ID:-}" \
          -var="postgres_server_fqdn=${POSTGRES_SERVER_FQDN:-}" \
          -var="azure_location=$POSTGRES_LOCATION" \
          -var="db_admin_login=${{ secrets.DB_ADMIN_LOGIN }}" \
          -var="db_admin_password=${{ secrets.DB_ADMIN_PASSWORD }}" && \
        echo "✓ Azure plan created successfully" || \
        (echo "✗ Azure plan failed" && ls -la tfplan 2>&1 || echo "Plan file not found")
    
    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      continue-on-error: true
      run: |
        cd infrastructure/terraform/aws && \
        if [ -f tfplan ]; then
          terraform apply -auto-approve tfplan || echo "AWS apply failed"
        else
          echo "⚠ AWS plan file not found, skipping apply"
        fi
        cd ../azure && \
        if [ -f tfplan ]; then
          terraform apply -auto-approve tfplan || echo "Azure apply failed"
        else
          echo "⚠ Azure plan file not found, skipping apply"
        fi
    
    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      continue-on-error: true
    
    - name: Deploy to AWS EKS
      continue-on-error: true
      run: |
        aws eks update-kubeconfig --name codeforces-aws-cluster --region us-east-1 || echo "AWS EKS config failed"
        kubectl apply --validate=false -f infrastructure/kubernetes/base/namespace.yaml || echo "Namespace creation failed"
        find infrastructure/kubernetes/base/ -name "*.yaml" ! -name "kustomization.yaml" -exec kubectl apply --validate=false -f {} \; || echo "AWS deployment failed"
        kubectl apply --validate=false -f infrastructure/kubernetes/network-policies.yaml || echo "Network policies failed"
        kubectl apply --validate=false -f infrastructure/kubernetes/rbac.yaml || echo "RBAC failed"
    
    - name: Deploy to Azure AKS
      continue-on-error: true
      env:
        DB_PASSWORD: ${{ secrets.DB_ADMIN_PASSWORD }}
        JWT_SECRET: ${{ secrets.JWT_SECRET_KEY }}
      run: |
        # Check if AKS cluster exists before trying to deploy
        if az aks show --resource-group codeforces-rg --name codeforces-aks-cluster --output json >/dev/null 2>&1; then
          echo "✓ AKS cluster exists, proceeding with deployment"
          az aks get-credentials --resource-group codeforces-rg --name codeforces-aks-cluster || echo "Azure AKS config failed"
          kubectl apply --validate=false -f infrastructure/kubernetes/base/namespace.yaml || echo "Namespace creation failed"
          
          # Create secrets
          kubectl create secret generic db-secret \
            --from-literal=url="postgresql://${{ secrets.DB_ADMIN_LOGIN }}:${DB_PASSWORD}@codeforces-postgres.postgres.database.azure.com:5432/codeforces_db?sslmode=require" \
            --namespace=codeforces \
            --dry-run=client -o yaml | kubectl apply -f - || echo "DB secret creation failed"
          
          kubectl create secret generic redis-secret \
            --from-literal=url="redis://redis:6379/0" \
            --namespace=codeforces \
            --dry-run=client -o yaml | kubectl apply -f - || echo "Redis secret creation failed"
          
          kubectl create secret generic jwt-secret \
            --from-literal=secret-key="${JWT_SECRET:-your-secret-jwt-key-change-in-production}" \
            --namespace=codeforces \
            --dry-run=client -o yaml | kubectl apply -f - || echo "JWT secret creation failed"
          
          kubectl create secret generic rabbitmq-secret \
            --from-literal=url="amqp://guest:guest@rabbitmq:5672/" \
            --namespace=codeforces \
            --dry-run=client -o yaml | kubectl apply -f - || echo "RabbitMQ secret creation failed"
          
          find infrastructure/kubernetes/base/ -name "*.yaml" ! -name "kustomization.yaml" -exec kubectl apply --validate=false -f {} \; || echo "Azure deployment failed"
          kubectl apply --validate=false -f infrastructure/kubernetes/network-policies.yaml || echo "Network policies failed"
          kubectl apply --validate=false -f infrastructure/kubernetes/rbac.yaml || echo "RBAC failed"
        else
          echo "⚠️ AKS cluster does not exist yet. Terraform will create it on next successful plan/apply."
          echo "⚠️ Skipping Azure Kubernetes deployment until cluster is created."
        fi
    

